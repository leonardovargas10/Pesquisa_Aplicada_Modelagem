{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: blue; font-size: 34px; font-weight: bold;'> Projeto Proposto \n",
    "</h1>\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i> Este projeto tem o intuito de estudar Redes Neurais Artificiais e suas aplicações em Deep Learning </i>       \n",
    "</p>  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange' style='font-size: 40px;'> Bibliotecas Utilizadas </font>\n",
    "<hr style='border: 2px solid orange;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bibliotecas De Manipulação de Dados e Visualização\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import builtins as builtins\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import itertools\n",
    "from IPython.display import display, Image\n",
    "\n",
    "## Bibliotecas de Modelagem Matemática e Estatística\n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "import scipy.stats as stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Bibliotecas de Manipulação de Tempo\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Bibliotecas de Métricas de Machine Learning\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Parâmetros de Otimização\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = '14'\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # Tira os números do formato de Notação Científica\n",
    "np.set_printoptions(suppress=True) # Tira os números do formato de Notação Científica em Numpy Arrays\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Retira Future Warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange' style='font-size: 40px;'> Primeiros Passos PyTorch </font>\n",
    "<hr style='border: 2px solid orange;'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Tema 1 </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Linear(a, b) cria pesos e bias para uma transformação linear x @ W^T + b.\n",
    "# F.relu(...) aplica a função ReLU elemento-a-elemento (max(0, x)).\n",
    "# hidden_dims é um argumento com valor padrão; cuidado com mutáveis como listas em assinaturas de função (não é crítico aqui, mas é um ponto de atenção em geral).\n",
    "\n",
    "class MLP_PyTorch(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[64, 32]):\n",
    "        super(MLP_PyTorch, self).__init__()               # Chama o construtor da classe base (nn.Module).\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])   # Primeira camada linear: transforma input_dim -> hidden_dims[0].\n",
    "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])  # Segunda camada linear: hidden_dims[0] -> hidden_dims[1].\n",
    "        self.out = nn.Linear(hidden_dims[1], 1)           # Camada de saída: hidden_dims[1] -> 1 (probabilidade do label 1).\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))                           # Aplica fc1 e ReLU (não linearidade). Saída shape: (batch, hidden_dims[0])\n",
    "        x = F.relu(self.fc2(x))                           # Aplica fc2 e ReLU. Saída shape: (batch, hidden_dims[1])\n",
    "        x = torch.sigmoid(self.out(x))                    # Aplica a camada final e sigmoid -> probabilidade entre 0 e 1.\n",
    "        return x                                         # Retorna tensor de probabilidades shape (batch, 1)\n",
    "    \n",
    "################ CUDA ##################\n",
    "# CUDA (Compute Unified Device Architecture) é a plataforma da NVIDIA que permite usar a placa de vídeo (GPU) não só para gráficos, mas também para cálculos científicos e de machine learning.\n",
    "# O PyTorch pode rodar tanto em CPU quanto em GPU.\n",
    "# Quando você instala o PyTorch com CUDA habilitado, ele sabe \"conversar\" com sua GPU NVIDIA para mandar os tensores e operações para lá.\n",
    "# Isso acelera absurdamente o treinamento de redes neurais — em vez de horas na CPU, você pode treinar em minutos na GPU.\n",
    "# Rodar no PROMPT nvidia-smi para saber a versão da sua GPU\n",
    "# conda create -n pytorch_cuda python=3.9\n",
    "# conda activate pytorch_cuda\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "\n",
    "def train_mlp_pytorch(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        class_weight, \n",
    "        lr=0.001, # Learning Rate\n",
    "        epochs=50, \n",
    "        batch_size=256, \n",
    "        device='cuda' # \"cuda\" é GPU e \"cpu\" é CPU\n",
    "    ):\n",
    "    # Converte os dados de treino (features) para tensores float32 e envia para a GPU/CPU\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Converte o target (labels) para tensores float32, adiciona dimensão extra (coluna) e envia para GPU/CPU\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    \n",
    "    # Cria um dataset do PyTorch unindo features e labels\n",
    "    dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "    # Cria um DataLoader que divide o dataset em batches e embaralha os dados\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Instancia o modelo MLP definido anteriormente e envia para GPU/CPU\n",
    "    model = MLP_PyTorch(input_dim=X_train.shape[1]).to(device)\n",
    "    \n",
    "    # Cria um tensor de pesos para lidar com desbalanceamento de classes (class_weight)\n",
    "    weight_tensor = torch.tensor(\n",
    "        [class_weight if label==1 else 1.0 for label in y_train.values],  # aplica peso maior para a classe 1\n",
    "        dtype=torch.float32\n",
    "    ).unsqueeze(1).to(device)\n",
    "\n",
    "    # Define a função de perda Binary Cross-Entropy (BCELoss) com pesos por amostra\n",
    "    criterion = nn.BCELoss(weight=weight_tensor)\n",
    "    \n",
    "    # Define o otimizador Adam com taxa de aprendizado lr\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Coloca o modelo em modo de treino\n",
    "    model.train()\n",
    "\n",
    "    # Loop principal de treino\n",
    "    for epoch in range(epochs):  # repete pelo número de épocas\n",
    "        for xb, yb in loader:    # itera sobre os batches do DataLoader\n",
    "            optimizer.zero_grad()       # zera os gradientes acumulados\n",
    "            preds = model(xb)           # passa o batch pelo modelo (forward)\n",
    "            loss = criterion(preds, yb) # calcula a perda (comparando preds vs rótulos reais)\n",
    "            loss.backward()             # faz backpropagation (calcula gradientes)\n",
    "            optimizer.step()            # atualiza os pesos do modelo\n",
    "    \n",
    "    # Retorna o modelo treinado\n",
    "    return model\n",
    "\n",
    "def predict_mlp_pytorch(model, X, device='cuda'):\n",
    "    # Coloca o modelo em modo de avaliação (desliga dropout e batchnorm em modo treino)\n",
    "    model.eval()\n",
    "    \n",
    "    # Converte o DataFrame X em tensor float32 e envia para o dispositivo especificado (GPU ou CPU)\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Bloco que desativa o cálculo de gradientes para economizar memória e acelerar\n",
    "    with torch.no_grad():\n",
    "        # Passa os dados pelo modelo e obtém as probabilidades preditas\n",
    "        # .cpu() garante que o resultado volte para a CPU\n",
    "        # .numpy() converte o tensor em array NumPy\n",
    "        probs = model(X_tensor).cpu().numpy()\n",
    "    \n",
    "    # Converte as probabilidades em rótulos binários: 1 se >= 0.5, 0 se < 0.5\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    \n",
    "    # Retorna os rótulos preditos e as probabilidades\n",
    "    return preds, probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange' style='font-size: 40px;'> Multilayer Perceptron </font>\n",
    "<hr style='border: 2px solid orange;'>\n",
    "\n",
    "https://www.kaggle.com/datasets/hojjatk/mnist-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Teste 1 </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange' style='font-size: 40px;'> Redes Neurais Convolucionais </font>\n",
    "<hr style='border: 2px solid orange;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Teste 1 </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange' style='font-size: 40px;'> Redes Neurais Recorrentes </font>\n",
    "<hr style='border: 2px solid orange;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Teste 1 </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange' style='font-size: 40px;'> Redes Generativas Adversariais </font>\n",
    "<hr style='border: 2px solid orange;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Teste 1 </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange' style='font-size: 40px;'> Autoencoders </font>\n",
    "<hr style='border: 2px solid orange;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Teste 1 </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange' style='font-size: 40px;'> Transformers </font>\n",
    "<hr style='border: 2px solid orange;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Teste 1 </font>\n",
    "<hr style='border: 2px solid green;'>\n",
    "\n",
    "https://medium.com/@ian.barreiro/transformers-uma-implementa%C3%A7%C3%A3o-em-python-b9eb9305482d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.2) Teste 2 </font>\n",
    "<hr style='border: 2px solid green;'>\n",
    "\n",
    "https://airtonlirajr.medium.com/criando-um-llm-do-zero-com-transformers-f97e3436eea4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
